{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d26eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForNextSentencePrediction\n",
    "from transformers import AutoTokenizer\n",
    "from tensorflow.keras.layers import Softmax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65422e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForNextSentencePrediction.\n",
      "\n",
      "All the weights of TFBertForNextSentencePrediction were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForNextSentencePrediction for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForNextSentencePrediction.from_pretrained('bert-base-uncased', from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1bac604",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"pizza is eaten with the use of a knife and fork. In casual settings, however, it is cut into wedges to be eaten while held in the hand.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87478127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  1999  3304  1010 10733  2366  1999  5337 10906  1010  2107  2004\n",
      "   2012  1037  4825  1010  2003  3591  4895 14540  6610  2094  1012   102\n",
      "  10733  2003  8828  2007  1996  2224  1997  1037  5442  1998  9292  1012\n",
      "   1999 10017 10906  1010  2174  1010  2009  2003  3013  2046 17632  2015\n",
      "   2000  2022  8828  2096  2218  1999  1996  2192  1012   102]], shape=(1, 58), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
    "print(encoding['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65513d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] : 101\n",
      "[SEP] : 102\n"
     ]
    }
   ],
   "source": [
    "# 문장의 시작을 알리는 cls 토큰과 각 문장의 끝을 알리는 sep 토큰 번호를 알아보자\n",
    "print(tokenizer.cls_token, ':', tokenizer.cls_token_id)\n",
    "print(tokenizer.sep_token, ':' , tokenizer.sep_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981970c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] in italy, pizza served in formal settings, such as at a restaurant, is presented unsliced. [SEP] pizza is eaten with the use of a knife and fork. in casual settings, however, it is cut into wedges to be eaten while held in the hand. [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(encoding['input_ids'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddba347e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 58), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 두문장에 대한 세크먼트 토큰 확인\n",
    "print(encoding['token_type_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36689b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[9.9999714e-01 2.8381860e-06]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
    "\n",
    "# vsc 이렇게 하면 오류난다. import\n",
    "# softmax = tf.keras.layers.Softmax()\n",
    "# probs = softmax(logits)\n",
    "\n",
    "# 이렇게 하면 오류난다. 왜냐하면 Softmax() 함수이다.\n",
    "# probs = Softmax(logits)\n",
    "\n",
    "# 이렇게 하거나\n",
    "# softmax = Softmax()\n",
    "# probs = softmax(logits)\n",
    "\n",
    "# 이렇게 해야 한다.\n",
    "probs = Softmax()(logits)\n",
    "\n",
    "print(probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf71c54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 레이블 : [0]\n"
     ]
    }
   ],
   "source": [
    "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e99e560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 레이블 : [1]\n"
     ]
    }
   ],
   "source": [
    "# 실제적으로 이어지지 않는 문장으로 테스트를 해보자\n",
    "# 상관없는 두 개의 문장\n",
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
    "\n",
    "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
    "\n",
    "# 이렇게 하면 오류 난다.\n",
    "# softmax = tf.keras.layers.Softmax()\n",
    "# probs = softmax(logits)\n",
    "\n",
    "softmax = Softmax()\n",
    "probs = softmax(logits)\n",
    "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
